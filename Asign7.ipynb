{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 6390: Assignment 7\n",
    "\n",
    "## Due November 15th\n",
    "\n",
    "### By: Nicholas Lutrzykowski\n",
    "\n",
    "The goal of this assignment is to implement the RNN algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "from scipy.special import logsumexp\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and setup data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename): \n",
    "    res = ''\n",
    "    with open(filename, 'r') as f:\n",
    "        str = f.read()\n",
    "        \n",
    "        res = str.split(' \\n')[1:]\n",
    "    \n",
    "    for i in range(len(res)): \n",
    "        #res[i] = np.array(res[i].split())\n",
    "        res[i] = res[i].split('\\n')[:-1]\n",
    "        \n",
    "        for j in range(len(res[i])):\n",
    "            res[i][j] = np.array(res[i][j].split(), dtype=float)\n",
    "    \n",
    "    return res    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y(num):\n",
    "    result = np.array([], dtype=np.int8)\n",
    "    for i in range(10):\n",
    "        result = np.concatenate((result, np.ones((num,), dtype=np.int8)*i))\n",
    "    \n",
    "    one_hot = np.zeros((result.size, result.max()+1))\n",
    "    one_hot[np.arange(result.size), result] = 1\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data set size: 2200\n",
      "Train data set size: 6600\n"
     ]
    }
   ],
   "source": [
    "test = read_data('Test_Arabic_Digit.txt')\n",
    "train = read_data('Train_Arabic_Digit.txt')\n",
    "\n",
    "y_test = get_y(int(len(test)/10))\n",
    "y_train = get_y(int(len(train)/10))\n",
    "\n",
    "print(\"Test data set size:\", len(test))\n",
    "print(\"Train data set size:\", len(train))\n",
    "\n",
    "'''\n",
    "The data is in the following format: \n",
    "data[i] is a single sequence (tao x 13 shape)\n",
    "data[i][j] is a single sample in time of a sequence (1 x 13 shape)\n",
    "'''\n",
    "#y_test = np.reshape(y_test, (y_test.shape[0], 1))\n",
    "#y_train = np.reshape(y_train, (y_train.shape[0], 1))\n",
    "# y shape is (# points, 10)\n",
    "\n",
    "train = np.reshape(np.array(train), (len(train), 1))\n",
    "train = np.concatenate((train, y_train), axis=1)\n",
    "\n",
    "test = np.reshape(np.array(test), (len(test), 1))\n",
    "test = np.concatenate((test, y_test), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN-Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN_training(D, eta, maxiter, d, m, p):\n",
    "\n",
    "    bh = np.random.uniform(low=-0.01, high=0.01, size=m)\n",
    "    bo = np.random.uniform(low=-0.01, high=0.01, size=p)\n",
    "    \n",
    "    Wi = np.random.uniform(low=-0.01, high=0.01, size=(d, m))\n",
    "    Wh = np.random.uniform(low=-0.01, high=0.01, size=(m, m))\n",
    "    Wo = np.random.uniform(low=-0.01, high=0.01, size=(m, p))\n",
    "    \n",
    "    \n",
    "    r = 0\n",
    "    avg_cross_entropy = 0\n",
    "    while r < maxiter:\n",
    "        np.random.shuffle(D)\n",
    "        cross_entropy = 0 \n",
    "        i = 0\n",
    "        for seq in D:\n",
    "            \n",
    "            i += 1\n",
    "            # Initialize the training sequence\n",
    "            X = np.array(seq[0])\n",
    "            Y = seq[1:]\n",
    "            tao = len(X)\n",
    "\n",
    "            # Forward propogation\n",
    "            h = np.zeros((tao+1, m)) # Initialize the hidden state\n",
    "            o = np.zeros((tao, p)) # Initialize the output state\n",
    "            h[0, :] = np.maximum(0, np.matmul(Wi.T, X[0, :]) + np.matmul(Wh.T, h[0, :]) + bh)\n",
    "            for t in range(tao):    \n",
    "                \n",
    "                h[t+1, :] = np.maximum(0, np.matmul(Wi.T, X[t, :]) + np.matmul(Wh.T, h[t, :]) + bh)\n",
    "                \n",
    "                o[t, :] = softmax(np.matmul(Wo.T, h[t+1, :]) + bo)\n",
    "                #o[t, :] = (np.matmul(Wo.T, h[t, :]) + bo) - logsumexp(np.matmul(h, Wo) + bo)\n",
    "            \n",
    "            # Backward propogation\n",
    "            deltao = np.zeros((tao,p)) # Net gradients at output\n",
    "            \n",
    "            for t in range(tao-1, -1, -1):\n",
    "                #deltaf = np.where(o[t, :] > 0, 1, 0) # CHANGE THIS TO SOFTMAX DERIVATIVE\n",
    "                deltaf = (o[t,:]) - logsumexp(o)\n",
    "                #o[t,:] = np.where(o[t,:] == 0, 1e-8, o[t,:])\n",
    "                #Error = np.multiply(Y, np.log(1/o[t,:])) + np.multiply((1-Y), np.log(1/(1-o[t,:])))\n",
    "                Error = o[t, :] - Y\n",
    "                deltao[t, :] = np.multiply(deltaf, Error)\n",
    "            \n",
    "            \n",
    "            deltah = np.zeros((tao,m)) # Net gradients at ht\n",
    "            deltah[-1, :] = np.multiply(np.where(h[-1, :] > 0, 1, 0), np.matmul(Wo, deltao[-1,:]))\n",
    "            \n",
    "            deltaf = np.where(h > 0, 1, 0)\n",
    "            for t in range(tao-1, 0, -1): \n",
    "                deltah[t, :] = np.multiply(deltaf[t, :], np.matmul(Wo, deltao[t, :]) + np.matmul(Wo, deltao[t, :]))\n",
    "            \n",
    "            # Gradients \n",
    "            bo_dif = np.sum(deltao, axis=0) \n",
    "            wo_dif = np.matmul(h[1:,:].T, deltao)\n",
    "            bh_dif = np.sum(deltah, axis=0)\n",
    "            wh_dif = np.matmul(h[:-1,:].T, deltah)\n",
    "            wi_dif = np.matmul(X.T, deltah)\n",
    "            \n",
    "            # Gradient Descent Step\n",
    "            bo = bo - eta*bo_dif\n",
    "            Wo = Wo - eta*wo_dif\n",
    "            bh = bh - eta*bh_dif\n",
    "            Wh = Wh - eta*wh_dif\n",
    "            Wi = Wi - eta*wi_dif\n",
    "            \n",
    "            o = np.where(o == 0, 1e-9, o)\n",
    "            cross_entropy += np.sum(np.multiply(Y, np.log(1/o)) + np.multiply((1-Y), np.log(1/(1-o))))\n",
    "            \n",
    "        avg_cross_entropy += cross_entropy/D.shape[0]\n",
    "        r += 1\n",
    "    \n",
    "    print(\"The average cross entropy on the training data set is:\", avg_cross_entropy/maxiter)\n",
    "    \n",
    "    return bo, Wo, bh, Wh, Wi\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average cross entropy on the training data set is: 129.8458505281867\n"
     ]
    }
   ],
   "source": [
    "bo, Wo, bh, Wh, Wi = RNN_training(train, 1e-7, 20, 13, 16, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_accuracy(D, bo, Wo, bh, Wh, Wi):\n",
    "    accuracy = 0\n",
    "    cross_entropy = 0\n",
    "    for seq in D:\n",
    "        \n",
    "        # Initialize the training sequence\n",
    "        X = np.array(seq[0])\n",
    "        Y = seq[1:]\n",
    "        tao = len(X)\n",
    "\n",
    "        # Forward propogation\n",
    "        h = np.zeros((tao+1, bh.shape[0])) # Initialize the hidden state\n",
    "        o = np.zeros((tao, bo.shape[0])) # Initialize the output state\n",
    "        h[0, :] = np.maximum(0, np.matmul(Wi.T, X[0, :]) + np.matmul(Wh.T, h[0, :]) + bh)\n",
    "        for t in range(tao):    \n",
    "            \n",
    "            h[t+1, :] = np.maximum(0, np.matmul(Wi.T, X[t, :]) + np.matmul(Wh.T, h[t, :]) + bh)\n",
    "            \n",
    "            o[t, :] = softmax(np.matmul(Wo.T, h[t+1, :]) + bo)\n",
    "        \n",
    "        if np.argmax(o[-1,:]) == np.argmax(Y):\n",
    "            accuracy += 1 \n",
    "            \n",
    "        cross_entropy += np.sum(np.multiply(Y, np.log(1/o)) + np.multiply((1-Y), np.log(1/(1-o))))\n",
    "    \n",
    "    return (accuracy/D.shape[0]), cross_entropy/D.shape[0]\n",
    "       \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: 0.1\n",
      "The training loss is: 129.73645807625448\n",
      "The test accuracy is: 0.1\n",
      "The test loss is: 128.72277763245887\n"
     ]
    }
   ],
   "source": [
    "train_accuracy, loss_train = training_accuracy(train, bo, Wo, bh, Wh, Wi)\n",
    "test_accuracy, loss_test = training_accuracy(test, bo, Wo, bh, Wh, Wi)\n",
    "\n",
    "print(\"The training accuracy is:\", train_accuracy)\n",
    "print(\"The training loss is:\", loss_train)\n",
    "print(\"The test accuracy is:\", test_accuracy)\n",
    "print(\"The test loss is:\", loss_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the training and test accuracy, it appears that my model is not actually learning. I implemented the correct RNN structure, but was unable to figure out which calculation I have as incorrect in the backpropogation. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "99ef57a3e309b3ccef27bfdc21155d00f14e44d33227cb907457916f15963b11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
